{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def enhance_alpha(im, mask, row_split=2, col_split=2, n_jobs=8):\n",
    "\tnrow, ncol = im.shape[:2]\n",
    "\n",
    "\tslices = []\n",
    "\tfor i in range(row_split):\n",
    "\t\tfor j in range(col_split):\n",
    "\t\t\tslices.append((slice(i*nrow//row_split, (i+1)*nrow//row_split),\n",
    "\t\t\t\t\t\t\tslice(j*nrow//col_split, (j+1)*nrow//col_split)))\n",
    "\n",
    "\tpatches = Parallel(n_jobs=n_jobs)(delayed(other_repo_function)(im[ss].copy(), mask[ss].copy()) for ss in slices)\n",
    "\n",
    "\tfor i, ss in enumerate(slices):\n",
    "\t\tmask[ss] = patches[i]\n",
    "\n",
    "\treturn mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "from pymatting import cutout\n",
    "from matting import alpha_matting, load_image, save_image, estimate_foreground_background, stack_images\n",
    "\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "import scipy.misc\n",
    "import scipy\n",
    "import image_slicer\n",
    "from image_slicer import join\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import asyncio\n",
    "\n",
    "\n",
    "# Trying alpha-matting now \n",
    "\n",
    "num_tiles = 16\n",
    "img = 'ex_3/original_big.jpg'\n",
    "tiles = image_slicer.slice(img, num_tiles, save=True)\n",
    "mask = 'ex_3/mask_big.png'\n",
    "amask = cv2.cvtColor(cv2.imread(mask), cv2.COLOR_BGR2GRAY)\n",
    "mtiles = image_slicer.slice(\"ex_3/conv_mask.png\", num_tiles, save=False)\n",
    "ftiles = deepcopy(tiles)\n",
    "\n",
    "\n",
    "\n",
    "def background(f):\n",
    "    def wrapped(*args, **kwargs):\n",
    "        return asyncio.get_event_loop().run_in_executor(None, f, *args, **kwargs)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "@background\n",
    "def para_alpha(i):\n",
    "    start_time = time.time()\n",
    "\n",
    "#     print(i)\n",
    "    image = np.array(tiles[i].image)[:, :, [0, 1, 2]] / 255.0\n",
    "    trimap = np.array(mtiles[i].image) / 255.0\n",
    "#     alpha = alpha_matting(image, trimap, method=\"ifm\", preconditioner=\"vcycle\", print_info=False)\n",
    "    foreground, background = estimate_foreground_background(image, trimap, print_info=False)\n",
    "\n",
    "    cutout = stack_images(foreground, trimap)\n",
    "    cutout = np.clip(cutout * 255, 0, 255).astype(np.uint8)\n",
    "    ftiles[i].image = Image.fromarray(cutout)\n",
    "\n",
    "\n",
    "    save_image(\"stitch/plant_cutout_big_\" + str(tiles[i].basename.split('_', 2)[-1]) + \".png\", cutout)\n",
    "    print(\"Time taken for slice: \", i, \":\",time.time() - start_time)\n",
    "    #code\n",
    "\n",
    "for i in range(num_tiles):\n",
    "    para_alpha(i)\n",
    "\n",
    "\n",
    "output = join(ftiles)\n",
    "\n",
    "output.save('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(ftiles[0].image).shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftiles[3].image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "into = cv2.imread('stitch/plant_cutout_big_01_01.png', cv2.IMWR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('checking.png', into)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "into.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(cv2.cvtColor(orig_2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.imshow(cv2.cvtColor(cv2.imread('stitch/plant_cutout_big_01_01.png', cv2.IMREAD_UNCHANGED), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(mtiles[0].image) , cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join(ftiles[0].image).save('checking.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout = np.clip(cutout * 255, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(cutout[:, :, [0, 1, 2]] * 255, dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(cutout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Image.fromarray(np.array(cutout[:, :, [0, 1, 2]] * 255.0, dtype=int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ftiles[0].image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftiles[0].image = ftiles[1].image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftiles = image_slicer.slice(img, num_tiles, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttiles = image_slicer.open_images_in('stitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(num))\n",
    "image = load_image(\"ex_2/original.jpg\", \"RGB\")\n",
    "trimap = load_image(\"ex_2/mask copy.png\", \"GRAY\")\n",
    "\n",
    "alpha = alpha_matting(image, trimap, method=\"cf\", preconditioner=\"vcycle\", print_info=False)\n",
    "\n",
    "foreground, background = estimate_foreground_background(image, alpha, print_info=False)\n",
    "\n",
    "cutout = stack_images(foreground, alpha)\n",
    "\n",
    "save_image(\"plant_cutout.png\", cutout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimap = load_image(\"ex_3/mask_big.png\", \"GRAY\", 0.5, \"nearest\")\n",
    "trimap[trimap>=0.8] = 1\n",
    "trimap[trimap<=0.2] = 0\n",
    "trimap[(trimap > 0.2) & (trimap < 0.8)] = 0.5\n",
    "\n",
    "np.unique(trimap)\n",
    "\n",
    "from pymatting import *\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "scale = 1.0\n",
    "\n",
    "\n",
    "image = load_image(\"ex_3/original_big.jpg\", \"RGB\", scale, \"box\")\n",
    "trimap = load_image(\"ex_3/mask_big.png\", \"GRAY\", scale, \"nearest\")\n",
    "trimap[trimap>=0.7] = 1\n",
    "trimap[trimap<=0.3] = 0\n",
    "trimap[(trimap > 0.2) & (trimap < 0.8)] = 0.5\n",
    "\n",
    "# height and width of trimap\n",
    "h, w = trimap.shape[:2]\n",
    "\n",
    "# calculate laplacian matrix\n",
    "L = cf_laplacian(image)\n",
    "\n",
    "# decompose trimap\n",
    "is_fg, is_bg, is_known, is_unknown = trimap_split(trimap)\n",
    "\n",
    "# constraint weight\n",
    "lambda_value = 100.0\n",
    "\n",
    "# build constraint pixel selection matrix\n",
    "c = lambda_value * is_known\n",
    "C = scipy.sparse.diags(c)\n",
    "\n",
    "# build constraint value vector\n",
    "b = lambda_value * is_fg\n",
    "\n",
    "# build linear system\n",
    "print(\"Shape of L:\", L.shape)\n",
    "print(\"Shape of C: \", C.shape)\n",
    "A = L + C\n",
    "\n",
    "# build ichol preconditioner for faster convergence\n",
    "A = A.tocsr()\n",
    "A.sum_duplicates()\n",
    "M = ichol(A)\n",
    "\n",
    "# solve linear system with conjugate gradient descent\n",
    "x = cg(A, b, M=M)\n",
    "\n",
    "# clip and reshape result vector\n",
    "alpha = np.clip(x, 0.0, 1.0).reshape(h, w)\n",
    "\n",
    "save_image(\"lemur_alpha.png\", alpha)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from matting import alpha_matting, load_image, save_image, stack_images,\\\n",
    "    estimate_foreground_background, METHODS, PRECONDITIONERS\n",
    "import os\n",
    "\n",
    "# Input paths\n",
    "image_path = \"ex_2/original.jpg\"\n",
    "trimap_path = \"ex_2/mask copy.png\"\n",
    "new_background_path = \"background.png\"\n",
    "# Output paths\n",
    "alpha_path = \"plant_alpha_%s_%s.png\"\n",
    "cutout_path = \"plant_cutout_%s_%s.png\"\n",
    "os.makedirs(\"out\", exist_ok=True)\n",
    "\n",
    "# Limit image size to make demo run faster\n",
    "height = 128\n",
    "\n",
    "# Load input images\n",
    "# shape (height, width, 3) of data type numpy.float64 in range [0, 1]\n",
    "image = load_image(image_path, \"RGB\", \"BILINEAR\")\n",
    "print(\"Shape of image: \", image.shape)\n",
    "\n",
    "# shape (height, width) of data type numpy.float64 in range [0, 1]\n",
    "trimap = load_image(trimap_path, \"GRAY\", \"NEAREST\")\n",
    "\n",
    "# Calculate alpha with various alpha matting methods and preconditioners\n",
    "for method in METHODS:\n",
    "    for preconditioner in PRECONDITIONERS[method]:\n",
    "        alpha = alpha_matting(\n",
    "            image, trimap,\n",
    "            method, preconditioner,\n",
    "            print_info=False)\n",
    "\n",
    "        # Save alpha\n",
    "        save_image(alpha_path % (method, preconditioner), alpha)\n",
    "\n",
    "        foreground, background = estimate_foreground_background(\n",
    "            image, alpha, print_info=False)\n",
    "\n",
    "        # Make new image from foreground and alpha\n",
    "        cutout = stack_images(foreground, alpha)\n",
    "\n",
    "        # Save cutout\n",
    "        save_image(cutout_path % (method, preconditioner), cutout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread('old_matting/examples/plant_image.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 100 #Threshold for masking\n",
    "\n",
    "# orig = cv2.imread('ex_1/Raquib_pic.jpg')\n",
    "# amask = cv2.imread('ex_1/MASK.png')\n",
    "orig = cv2.imread('ex_2/original.jpg')\n",
    "# amask = cv2.imread('ex_2/mask copy.png')\n",
    "amask = cv2.imread('ex_2/mask-our-site.png')\n",
    "\n",
    "# orig = cv2.imread('ex_3/original_big.jpg')\n",
    "# amask = cv2.imread('ex_3/mask_big.png')\n",
    "\n",
    "\n",
    "if orig.shape == amask.shape:\n",
    "    orig_2 = orig.copy()\n",
    "else:\n",
    "    orig_2 = cv2.resize(orig, (amask.shape[1], amask.shape[0]), interpolation = cv2.INTER_CUBIC) \n",
    "\n",
    "amask[amask<threshold] = 0\n",
    "amask[amask>=threshold] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(trimap, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatting import *\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "\n",
    "scale = 1.0\n",
    "\n",
    "image = load_image(\"ex_2/original.jpg\", \"RGB\", scale, \"box\")\n",
    "trimap = load_image(\"ex_2/mask copy.png\", \"GRAY\", scale, \"nearest\")\n",
    "# trimap[trimap<threshold/255] = 0\n",
    "# trimap[trimap>=threshold/255] = 255\n",
    "\n",
    "# height and width of trimap\n",
    "h, w = trimap.shape[:2]\n",
    "\n",
    "# calculate laplacian matrix\n",
    "L = cf_laplacian(image)\n",
    "\n",
    "# decompose trimap\n",
    "is_fg, is_bg, is_known, is_unknown = trimap_split(trimap)\n",
    "\n",
    "# constraint weight\n",
    "lambda_value = 100.0\n",
    "\n",
    "# build constraint pixel selection matrix\n",
    "c = lambda_value * is_known\n",
    "C = scipy.sparse.diags(c)\n",
    "\n",
    "# build constraint value vector\n",
    "b = lambda_value * is_fg\n",
    "\n",
    "# build linear system\n",
    "A = L + C\n",
    "\n",
    "# build ichol preconditioner for faster convergence\n",
    "A = A.tocsr()\n",
    "A.sum_duplicates()\n",
    "M = ichol(A)\n",
    "\n",
    "# solve linear system with conjugate gradient descent\n",
    "x = cg(A, b, M=M)\n",
    "\n",
    "# clip and reshape result vector\n",
    "alpha = np.clip(x, 0.0, 1.0).reshape(h, w)\n",
    "\n",
    "save_image(\"lemur_alpha.png\", alpha)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cutout(\n",
    "    # input image path\n",
    "    \"ex_2/original.jpg\",\n",
    "    # input trimap path\n",
    "    \"ex_2/mask copy.png\",\n",
    "    # output cutout path\n",
    "    \"lets_see.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "# plt.imshow(cv2.cvtColor(mask2, cv2.COLOR_BGR2RGB))\n",
    "# plt.imshow(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB))\n",
    "# plt.imshow(cv2.cvtColor(orig_2, cv2.COLOR_BGR2RGB))\n",
    "# plt.imshow(cv2.GaussianBlur(mask,(7,7),0))\n",
    "plt.imshow(amask, cmap='gray')\n",
    "\n",
    "mask = amask.copy()\n",
    "# mask = cv2.GaussianBlur(mask,(7,7),0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((1,1), np.uint8) \n",
    "  \n",
    "img_erosion = cv2.erode(amask, kernel, iterations=1) \n",
    "img_dilation = cv2.dilate(amask, kernel, iterations=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_erosion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = img_erosion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpened1 = pil_mask.filter(ImageFilter.SHARPEN)\n",
    "sharpened2 = sharpened1.filter(ImageFilter.SHARPEN)\n",
    "sharpened3 = sharpened2.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "\n",
    "kernel = np.ones((1, 1), np.uint8) \n",
    "  \n",
    "# Using cv2.erode() method  \n",
    "mask = cv2.erode(amask, kernel)\n",
    "\n",
    "\n",
    "sharpened3.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "csharp = np.array(sharpened2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# opencv loads the image in BGR, convert it to RGB\n",
    "# img = cv2.cvtColor(cv2.imread('E:\\\\FOTOS\\\\opencv\\\\iT5q1.png'),\n",
    "#                    cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# load mask and make sure is black&white\n",
    "# _, mask = cv2.threshold(cv2.imread('E:\\\\FOTOS\\\\opencv\\\\SH9jL.png', 0),\n",
    "#                         0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# load background (could be an image too)\n",
    "bk = np.full(img.shape, 0, dtype=np.uint8)  # white bk, same size and type of image\n",
    "# bk = cv2.rectangle(bk, (0, 0), (int(img.shape[1] / 2), int(img.shape[0] / 2)), 0, -1)  # rectangles\n",
    "# bk = cv2.rectangle(bk, (int(img.shape[1] / 2), int(img.shape[0] / 2)), (img.shape[1], img.shape[0]), 0, -1)\n",
    "\n",
    "# get masked foreground\n",
    "fg_masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "# get masked background, mask must be inverted \n",
    "mask = cv2.bitwise_not(mask)\n",
    "bk_masked = cv2.bitwise_and(bk, bk, mask=mask)\n",
    "\n",
    "# combine masked foreground and masked background \n",
    "final = cv2.bitwise_or(fg_masked, bk_masked)\n",
    "mask = cv2.bitwise_not(mask)  # revert mask to original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual = Image.fromarray(orig_2)\n",
    "# actual.putalpha(0)\n",
    "\n",
    "# actual.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_2 = np.uint8(orig_2)\n",
    "mask = np.uint8(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src1_mask=cv2.cvtColor(src1_mask,cv2.COLOR_GRAY2BGR)#change mask to a 3 channel image \n",
    "# mask_out=cv2.subtract(src1_mask,src1)\n",
    "# mask_out=cv2.subtract(src1_mask,mask_out)\n",
    "\n",
    "\n",
    "mask_out=cv2.subtract(amask,orig_2)\n",
    "mask_out=cv2.subtract(amask,mask_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const = orig_2 * amask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(-cv2.cvtColor(const, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_const = Image.fromarray(const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpened1 = pi_const.filter(ImageFilter.SHARPEN)\n",
    "sharpened2 = sharpened1.filter(ImageFilter.SHARPEN)\n",
    "sharpened3 = sharpened2.filter(ImageFilter.SHARPEN)\n",
    "\n",
    "\n",
    "kernel = np.ones((1, 1), np.uint8) \n",
    "  \n",
    "# Using cv2.erode() method  \n",
    "mask = cv2.erode(amask, kernel)\n",
    "\n",
    "\n",
    "im2 = pi_const.filter(ImageFilter.MinFilter(3))\n",
    "im2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmask = np.array(amask, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(amask, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(bmask, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(orig_2*bmask).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_2[amask].reshape(orig_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.axis(\"off\")\n",
    "# plt.imshow(cv2.cvtColor(cv2.bitwise_or(orig_2, orig_2, mask=mask), cv2.COLOR_BGR2RGB))\n",
    "plt.imshow(cv2.cvtColor((orig_2*bmask), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ano = Image.fromarray(cv2.cvtColor(cv2.bitwise_or(cv2.bitwise_or(orig_2, orig_2, mask=mask), cv2.bitwise_or(orig_2, orig_2, mask=mask), mask=mask) , cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
